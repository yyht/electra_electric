{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "Adapted from https://github.com/gpeyre/SinkhornAutoDiff\n",
    "and from https://github.com/dfdazac/wassdistance/blob/master/layers.py\n",
    "and from https://github.com/michaelsdr/sinkformers/blob/main/nlp-tutorial/text-classification-transformer/sinkhorn.py\n",
    "\"\"\"\n",
    "\n",
    "def shape_list(x, out_type=tf.int32):\n",
    "  \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "  static = x.shape.as_list()\n",
    "  dynamic = tf.shape(x, out_type=out_type)\n",
    "  return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def sinkhorn_distance(input_tensor, eps, max_iter, \n",
    "                  reduction='none',\n",
    "                  stopThr=1e-2):\n",
    "  \n",
    "  C = input_tensor\n",
    "  C_shape = shape_list(C)\n",
    "\n",
    "  x_points = C_shape[-2]\n",
    "  y_points = C_shape[-1]\n",
    "  batch_size = C_shape[0]\n",
    "    \n",
    "  # both marginals are fixed with equal weights\n",
    "  mu = 1.0 / x_points * tf.ones((batch_size, x_points))\n",
    "  nu = 1.0 / y_points * tf.ones((batch_size, y_points))\n",
    "\n",
    "  u = tf.zeros_like(mu)\n",
    "  v = tf.zeros_like(nu)\n",
    "\n",
    "  cpt = tf.constant(0)\n",
    "  err = tf.constant(1.0)\n",
    "\n",
    "  c = lambda cpt, u, v, err: tf.logical_and(cpt < max_iter, err > stopThr)\n",
    "\n",
    "  def M( C, u, v):\n",
    "    \"Modified cost for logarithmic updates\"\n",
    "    \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "    return (-C + tf.expand_dims(u, -1) + tf.expand_dims(v, -2) )/eps\n",
    "\n",
    "  def loop_func(cpt, u, v, err):\n",
    "    u1 = tf.identity(u)  # useful to check the update\n",
    "\n",
    "    cpt = cpt + 1\n",
    "\n",
    "    u = eps * (tf.log(mu+1e-8) - tf.reduce_logsumexp(M(C, u, v), axis=-1)) + u\n",
    "    v = eps * (tf.log(nu+1e-8) - tf.reduce_logsumexp(tf.transpose(M(C, u, v), [0, 2, 1]), axis=-1)) + v\n",
    "\n",
    "    err = tf.reduce_mean(tf.reduce_sum(tf.abs(u - u1), axis=-1))\n",
    "\n",
    "    return cpt, u, v, err\n",
    "\n",
    "  _, u_final, v_final, _ = tf.while_loop(c, loop_func, loop_vars=[cpt, u, v, err])\n",
    "  U, V = tf.identity(u_final), tf.identity(v_final)\n",
    "\n",
    "  # Transport plan pi = diag(a)*K*diag(b)\n",
    "  pi = tf.exp(M(C, U, V))\n",
    "\n",
    "  cost = tf.reduce_sum(pi * C, axis=(-2, -1))\n",
    "\n",
    "  return pi, C, U, V, cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1.0\n",
    "max_iter = 10\n",
    "stopThr = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cost_matrix(x, y, p=2):\n",
    "    \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "    x_col = tf.expand_dims(x, axis=-2)\n",
    "    y_lin = tf.expand_dims(y, axis=-3)\n",
    "    C = tf.reduce_sum((tf.abs(x_col - y_lin)) ** p, -1)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((1, 10, 32)).astype(np.float32)\n",
    "y = np.random.random((1, 16, 32)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = _cost_matrix(tf.constant(x), tf.constant(y), p=2)\n",
    "\n",
    "[pi, C_, U, V, final_cost] = sinkhorn_distance(C, eps, max_iter, \n",
    "                  reduction='none',\n",
    "                  stopThr=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "resp = sess.run([pi, C, U, V, final_cost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp[0].sum(axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Adapted from https://github.com/gpeyre/SinkhornAutoDiff\n",
    "class SinkhornDistance(nn.Module):\n",
    "    r\"\"\"\n",
    "    Given two empirical measures each with :math:`P_1` locations\n",
    "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "    outputs an approximation of the regularized OT cost for point clouds.\n",
    "    Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "    Shape:\n",
    "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "    def __init__(self, eps, max_iter, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # The Sinkhorn algorithm takes as input three variables :\n",
    "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
    "        x_points = x.shape[-2]\n",
    "        y_points = y.shape[-2]\n",
    "        if x.dim() == 2:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "        # both marginals are fixed with equal weights\n",
    "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / x_points).squeeze()\n",
    "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / y_points).squeeze()\n",
    "\n",
    "        u = torch.zeros_like(mu)\n",
    "        v = torch.zeros_like(nu)\n",
    "        # To check if algorithm terminates because of threshold\n",
    "        # or max iterations reached\n",
    "        actual_nits = 0\n",
    "        # Stopping criterion\n",
    "        thresh = 1e-1\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            u1 = u  # useful to check the update\n",
    "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            err = (u - u1).abs().sum(-1).mean()\n",
    "\n",
    "            actual_nits += 1\n",
    "            if err.item() < thresh:\n",
    "                break\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(self.M(C, U, V))\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(pi * C, dim=(-2, -1))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            cost = cost.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            cost = cost.sum()\n",
    "\n",
    "        return cost, pi, C\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "    @staticmethod\n",
    "    def _cost_matrix(x, y, p=2):\n",
    "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "        x_col = x.unsqueeze(-2)\n",
    "        y_lin = y.unsqueeze(-3)\n",
    "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
    "        return C\n",
    "\n",
    "    @staticmethod\n",
    "    def ave(u, u1, tau):\n",
    "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
    "        return tau * u + (1 - tau) * u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = SinkhornDistance(eps=eps, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cost, pi, C = sink.forward(torch.tensor(x), torch.tensor(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (ByteLevelBPETokenizer,\n",
    "      CharBPETokenizer,\n",
    "      SentencePieceBPETokenizer,\n",
    "      BertWordPieceTokenizer)\n",
    "\n",
    "vocab = '/data/xuht/uncased_L-12_H-768_A-12_ilm_v1/vocab_uncased_en.txt'\n",
    "\n",
    "chinese_bpe_tokenizer = BertWordPieceTokenizer(\n",
    "    vocab, \n",
    "    lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(chinese_bpe_tokenizer.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.not_equal([1.,2.,3.,0.], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "a = [1,0,3]\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(max(a)+1))\n",
    "b = label_binarizer.transform(a)\n",
    "print('{0}'.format(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.random.randint(1, 4, size=[2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tf = tf.one_hot(label, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_label = sess.run(label_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(one_hot_label.sum(axis=0) !=0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_relative_positions_matrix_t5(length, max_relative_position,\n",
    "                                        num_buckets=32,\n",
    "                                        bidirectional=True):\n",
    "  \n",
    "  \"\"\"\n",
    "  https://github.com/bojone/bert4keras/blob/master/bert4keras/layers.py\n",
    "  https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/transformer_layers.py\n",
    "  # _relative_position_bucket\n",
    "  https://gist.github.com/huchenxucs/c65524185e8e35c4bcfae4059f896c16\n",
    "  \"\"\"\n",
    "\n",
    "  tf.logging.info(\"** apply all distance mat **\")\n",
    "  range_vec = tf.range(length)\n",
    "\n",
    "  q_idxs = tf.expand_dims(range_vec, 1)\n",
    "  v_idxs = tf.expand_dims(range_vec, 0)\n",
    "\n",
    "  distance_mat = v_idxs - q_idxs  \n",
    "  # range_mat = tf.reshape(tf.tile(range_vec, [length]), [length, length])\n",
    "  # distance_mat = range_mat - tf.transpose(range_mat)\n",
    "    \n",
    "  num_buckets = num_buckets\n",
    "  max_distance = max_relative_position\n",
    "  ret = 0\n",
    "  n = -distance_mat\n",
    "  if bidirectional:\n",
    "    num_buckets //= 2\n",
    "    ret += tf.cast(tf.less(n, 0), 'int32') * num_buckets\n",
    "    n = tf.abs(n)\n",
    "  else:\n",
    "    n = tf.maximum(n, 0)\n",
    "  # now n is in the range [0, inf)\n",
    "  max_exact = num_buckets // 2\n",
    "  is_small = tf.less(n, max_exact)\n",
    "  val_if_large = max_exact + tf.cast(\n",
    "      tf.log(tf.cast(n, dtype=tf.float32) / max_exact) /\n",
    "      tf.log(max_distance / max_exact) * (num_buckets - max_exact),\n",
    "      'int32',\n",
    "  )\n",
    "  val_if_large = tf.minimum(val_if_large, num_buckets - 1)\n",
    "  tf_switch = (tf.cast(is_small, dtype=tf.int32)) * n + (1-tf.cast(is_small, dtype=tf.int32)) * val_if_large\n",
    "  ret += tf_switch #tf.switch(is_small, n, val_if_large)\n",
    "  # ret += tf.where(is_small, n, val_if_large)\n",
    "\n",
    "  return ret\n",
    "\n",
    "length=64\n",
    "max_relative_position=32\n",
    "num_buckets=32\n",
    "bidirectional=True\n",
    "\n",
    "ret_bi = _generate_relative_positions_matrix_t5(length, max_relative_position,\n",
    "                                        num_buckets=num_buckets,\n",
    "                                        bidirectional=bidirectional)\n",
    "\n",
    "ret_uni = _generate_relative_positions_matrix_t5(length, max_relative_position,\n",
    "                                        num_buckets=num_buckets,\n",
    "                                        bidirectional=False)\n",
    "\n",
    "ret = sess.run([ret_bi, ret_uni])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _relative_position_bucket_(relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
    "        \"\"\"\n",
    "        Adapted from Mesh Tensorflow:\n",
    "        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n",
    "        Translate relative position to a bucket number for relative attention.\n",
    "        The relative position is defined as memory_position - query_position, i.e.\n",
    "        the distance in tokens from the attending position to the attended-to\n",
    "        position.  If bidirectional=False, then positive relative positions are\n",
    "        invalid.\n",
    "        We use smaller buckets for small absolute relative_position and larger buckets\n",
    "        for larger absolute relative_positions.  All relative positions >=max_distance\n",
    "        map to the same bucket.  All relative positions <=-max_distance map to the\n",
    "        same bucket.  This should allow for more graceful generalization to longer\n",
    "        sequences than the model has been trained on.\n",
    "        Args:\n",
    "            relative_position: an int32 Tensor\n",
    "            bidirectional: a boolean - whether the attention is bidirectional\n",
    "            num_buckets: an integer\n",
    "            max_distance: an integer\n",
    "        Returns:\n",
    "            a Tensor with the same shape as relative_position, containing int32\n",
    "            values in the range [0, num_buckets)\n",
    "        \"\"\"\n",
    "        ret = 0\n",
    "        n = -relative_position\n",
    "        if bidirectional:\n",
    "            num_buckets //= 2\n",
    "            ret += (n < 0).to(torch.long) * num_buckets  # mtf.to_int32(mtf.less(n, 0)) * num_buckets\n",
    "            n = torch.abs(n)\n",
    "        else:\n",
    "            n = torch.max(n, torch.zeros_like(n))\n",
    "        # now n is in the range [0, inf)\n",
    "\n",
    "        # half of the buckets are for exact increments in positions\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = n < max_exact\n",
    "\n",
    "        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "        val_if_large = max_exact + (\n",
    "            torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)\n",
    "        ).to(torch.long)\n",
    "        val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, num_buckets - 1))\n",
    "\n",
    "        ret += torch.where(is_small, n, val_if_large)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_position = torch.arange(64, dtype=torch.long)[:, None]\n",
    "memory_position = torch.arange(64, dtype=torch.long)[None, :]\n",
    "relative_position = memory_position - context_position  # shape (qlen, klen)\n",
    "resp = _relative_position_bucket_(relative_position, bidirectional=False, num_buckets=32, max_distance=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[0][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-segment_ids) * resp[25].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_position = torch.arange(64, dtype=torch.long)[:, None]\n",
    "memory_position = torch.arange(64, dtype=torch.long)[None, :]\n",
    "relative_position = memory_position - context_position  # shape (qlen, klen)\n",
    "s1 = _relative_position_bucket_(relative_position, bidirectional=True, num_buckets=32, max_distance=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_position = torch.arange(64, dtype=torch.long)[:, None]\n",
    "memory_position = torch.arange(64, dtype=torch.long)[None, :]\n",
    "relative_position = memory_position - context_position  # shape (qlen, klen)\n",
    "s3 = _relative_position_bucket_(relative_position, bidirectional=False, num_buckets=32, max_distance=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_position = torch.arange(32, dtype=torch.long)[:, None]\n",
    "memory_position = torch.arange(32, dtype=torch.long)[None, :]\n",
    "relative_position = memory_position - context_position  # shape (qlen, klen)\n",
    "s2 = _relative_position_bucket_(relative_position, bidirectional=True, num_buckets=32, max_distance=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = s1 * (1-segment_ids[None, :]) * (1-segment_ids[:, None]) + s3 * (segment_ids[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segment_ids = [0]*25+[1]*39\n",
    "\n",
    "segment_mask = tf.cast(np.array([segment_ids, segment_ids]), dtype=tf.int32)\n",
    "relative_positions_matrix_bi = tf.constant(ret[0])\n",
    "relative_positions_matrix_uni = tf.constant(ret[1])\n",
    "\n",
    "# handle mixture of bi and uni-direction relative position\n",
    "# [1, seq_len, seq_len]\n",
    "relative_positions_matrix_bi = tf.expand_dims(relative_positions_matrix_bi, axis=0)\n",
    "relative_positions_matrix_uni = tf.expand_dims(relative_positions_matrix_uni, axis=0)\n",
    "\n",
    "# s1 * (1-segment_ids[None, :]) * (1-segment_ids[:, None]) + s3 * (segment_ids[:, None])\n",
    "# [batch, seq_len, seq_len]\n",
    "relative_positions_matrix = relative_positions_matrix_bi * (1-tf.expand_dims(segment_mask, axis=1)) * (1-tf.expand_dims(segment_mask, axis=-1)) + relative_positions_matrix_uni * (tf.expand_dims(segment_mask, axis=-1))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = sess.run(relative_positions_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "63356*768-21228*512*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "init_np = np.random.random((4, 2, 3))\n",
    "update_np = np.random.random((1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    with tf.variable_scope(\"test\", reuse=tf.AUTO_REUSE):\n",
    "        queue = tf.get_variable('queue', \n",
    "                      [4, 2, 3], \n",
    "                      dtype=tf.float32,\n",
    "                      initializer=tf.constant_initializer(0),\n",
    "                      trainable=False)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    queue_op = queue.assign(tf.concat([tf.constant(update_np.astype(np.float32)), queue[:-1, :, :]], axis=0))\n",
    "    with tf.control_dependencies([queue_op]):\n",
    "    #     p = queue + 1\n",
    "        f = tf.identity(queue)\n",
    "        queue_mask = tf.cast(tf.not_equal(queue, 0), dtype=tf.float32)\n",
    "        Z = tf.reduce_logsumexp(queue-(1-queue_mask)*1e10, axis=-1)\n",
    "\n",
    "    with tf.control_dependencies([queue_op]):\n",
    "        p = queue + 1\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6429567e+00,  1.5841072e+00],\n",
       "       [-1.0000000e+10, -1.0000000e+10],\n",
       "       [-1.0000000e+10, -1.0000000e+10],\n",
       "       [-1.0000000e+10, -1.0000000e+10]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_mask = tf.cast(tf.not_equal(queue, 0), dtype=tf.float32)\n",
    "Z = tf.reduce_logsumexp(queue-(1-queue_mask)*1e10, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15929994, 0.77011406, 0.60853255],\n",
       "       [0.08643683, 0.19761226, 0.9424123 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
